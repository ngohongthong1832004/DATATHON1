{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "     ------------------------------------ 250.0/250.0 kB 959.0 kB/s eta 0:00:00\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -sgiref (c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -sgiref (c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -sgiref (c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -sgiref (c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime \n",
    "import os\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 30-04-2022_Ton Kho 1201 - 1230.xlsx successfully\n"
     ]
    }
   ],
   "source": [
    "target_file = \"inventory.csv\"\n",
    "\n",
    "def extract_from_excel(file_to_process):\n",
    "    dataframe = pd.read_excel(file_to_process)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe = dataframe.drop(columns=['Unnamed: 0'])\n",
    "    return dataframe\n",
    "\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['index', 'plant', 'calendar_year', 'calendar_year_week', 'sloc', 'quantity', 'total_amount', 'product_id'])\n",
    "\n",
    "    for csvfile in glob.glob(\"./InventoryAndSale_snapshot_data/Inventory_snapshot_data/*.xlsx\"):\n",
    "        file_name = os.path.basename(csvfile)\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_excel(csvfile))], ignore_index=True)\n",
    "        print(f\"read {file_name} successfully\")\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "dataframe = extract()\n",
    "\n",
    "def load_data(target_file, dataframe):\n",
    "    dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "load_data(target_file, dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read TT T01-2022_split_1.xlsx successfully\n",
      "read TT T01-2023_split_1.xlsx successfully\n"
     ]
    }
   ],
   "source": [
    "target_file = \"sale.csv\"\n",
    "\n",
    "def extract_from_excel(file_to_process):\n",
    "    dataframe = pd.read_excel(file_to_process)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['month', 'week', 'site', 'branch_id', 'channel_id', 'distribution_channel', 'distribution_channel_code', 'sold_quantity', 'cost_price', 'net_price', 'customer_id', 'product_id'])\n",
    "    for csvfile in glob.glob(\"./InventoryAndSale_snapshot_data/Sales_snapshot_data/*.xlsx\"):\n",
    "        file_name = os.path.basename(csvfile)\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_excel(csvfile))], ignore_index=True)\n",
    "        print(f\"read {file_name} successfully\")\n",
    "        \n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "dataframe = extract()\n",
    "\n",
    "def load_data(target_file, dataframe):\n",
    "    dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "load_data(target_file, dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read COGS.xlsx successfully\n"
     ]
    }
   ],
   "source": [
    "target_file = \"COGS.csv\"\n",
    "\n",
    "def extract_from_excel(file_to_process):\n",
    "    dataframe = pd.read_excel(file_to_process)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['index', 'amount', 'valid_from', 'valid_to', 'product_id'])\n",
    "    for csvfile in glob.glob(\"./InventoryAndSale_snapshot_data/MasterData/COGS.xlsx\"):\n",
    "        file_name = os.path.basename(csvfile)\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_excel(csvfile))], ignore_index=True)\n",
    "        print(f\"read {file_name} successfully\")\n",
    "        \n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "dataframe = extract()\n",
    "\n",
    "def load_data(target_file, dataframe):\n",
    "    dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "load_data(target_file, dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\workPlace\\DATATHON\\ETL.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mread \u001b[39m\u001b[39m{\u001b[39;00mfile_name\u001b[39m}\u001b[39;00m\u001b[39m successfully\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m extracted_data\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m dataframe \u001b[39m=\u001b[39m extract()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(target_file, dataframe):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     dataframe\u001b[39m.\u001b[39mto_csv(target_file, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32md:\\workPlace\\DATATHON\\ETL.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m csvfile \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m./InventoryAndSale_snapshot_data/MasterData/Distribution Channel.xlsx\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(csvfile)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     extracted_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([extracted_data, pd\u001b[39m.\u001b[39;49mDataFrame(extract_from_excel(csvfile))], ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mread \u001b[39m\u001b[39m{\u001b[39;00mfile_name\u001b[39m}\u001b[39;00m\u001b[39m successfully\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/workPlace/DATATHON/ETL.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m extracted_data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    610\u001b[0m         obj_labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ax]\n\u001b[0;32m    611\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_labels\u001b[39m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39;49mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_axes, concat_axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m    618\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3904\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3904\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3906\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   3907\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# target_file = \"Distribution_Channel.csv\"\n",
    "\n",
    "# def extract_from_excel(file_to_process):\n",
    "#     dataframe = pd.read_excel(file_to_process)\n",
    "#     dataframe.dropna(inplace=True)\n",
    "#     dataframe = dataframe.drop(columns=['Unnamed: 0'])\n",
    "#     return dataframe\n",
    "\n",
    "# def extract():\n",
    "#     extracted_data = pd.DataFrame(columns=['index', 'site_store', 'b2b_b2c', 'channel_id', 'region', 'city_level', 'store_concept', 'trade_term', 'area_range', 'store_type', 'store_type', 'urbanization', 'branch_area', 'address_2', 'address_3', 'showroom_area', 'warehouse_area', 'start_month', 'start_year', 'end_month', 'end_year', 'note', 'customer_id', 'customer_name'])\n",
    "#     for csvfile in glob.glob(\"./InventoryAndSale_snapshot_data/MasterData/Distribution Channel.xlsx\"):\n",
    "#         file_name = os.path.basename(csvfile)\n",
    "#         extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_excel(csvfile))], ignore_index=True)\n",
    "#         print(f\"read {file_name} successfully\")\n",
    "#     return extracted_data\n",
    "\n",
    "# dataframe = extract()\n",
    "\n",
    "# def load_data(target_file, dataframe):\n",
    "#     dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "# load_data(target_file, dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = \"Distribution_Channel.csv\"\n",
    "def extract():\n",
    "    extracted_data = pd.read_excel(\"./InventoryAndSale_snapshot_data/MasterData/Distribution Channel.xlsx\")\n",
    "    # extracted_data.dropna(inplace=True)\n",
    "    extracted_data = extracted_data.drop(columns=['Unnamed: 0'])\n",
    "    return extracted_data\n",
    "\n",
    "dataframe = extract()\n",
    "\n",
    "def load_data(target_file, dataframe):\n",
    "    dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "load_data(target_file, dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = \"New_Core_Classification.csv\"\n",
    "def extract():\n",
    "    extracted_data = pd.read_excel(\"./InventoryAndSale_snapshot_data/MasterData/New_Core_Classification.xlsx\")\n",
    "    # extracted_data.dropna(inplace=True)\n",
    "    extracted_data = extracted_data.drop(columns=['Unnamed: 0'])\n",
    "    return extracted_data\n",
    "\n",
    "dataframe = extract()\n",
    "\n",
    "def load_data(target_file, dataframe):\n",
    "    dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "load_data(target_file, dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = \"Productmaster.csv\"\n",
    "def extract():\n",
    "    extracted_data = pd.read_excel(\"./InventoryAndSale_snapshot_data/MasterData/Productmaster.xlsx\")\n",
    "    # extracted_data.dropna(inplace=True)\n",
    "    extracted_data = extracted_data.drop(columns=['Unnamed: 0'])\n",
    "    return extracted_data\n",
    "\n",
    "dataframe = extract()\n",
    "\n",
    "def load_data(target_file, dataframe):\n",
    "    dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "load_data(target_file, dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = \"Retail_price\"\n",
    "def extract():\n",
    "    extracted_data = pd.read_excel(\"./InventoryAndSale_snapshot_data/MasterData/Retail_price.xlsx\")\n",
    "    # extracted_data.dropna(inplace=True)\n",
    "    extracted_data = extracted_data.drop(columns=['Unnamed: 0'])\n",
    "    return extracted_data\n",
    "\n",
    "dataframe = extract()\n",
    "\n",
    "def load_data(target_file, dataframe):\n",
    "    dataframe.to_csv(target_file, index=False)\n",
    "\n",
    "load_data(target_file, dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
